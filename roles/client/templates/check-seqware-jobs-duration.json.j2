#!/bin/bash
#set -x
gtdownload={{ gtdownload }}
upload={{ upload }}
upload_rate_alert={{ upload_rate_alert }}
download_rate_alert={{ download_rate_alert }}
workflow_version={{ workflow_version }}

accession=`sudo -u seqware -i /home/seqware/bin/seqware workflow list | grep -B5 "Workflow_Bundle_$workflow_version"| grep "SeqWare Accession" | awk -F"|" '{print $2}'`

for workflow in `sudo -u seqware -i /home/seqware/bin/seqware workflow report --accession $accession | grep -A 4 -B 1 running| grep 'Workflow Run Engine ID'| awk -F"|" '{print $2}'`;\
do \
	for step in `oozie job -info $workflow -oozie http://localhost:11000/oozie | grep RUNNING| grep 0000| awk -F"@" '{print $2}'| awk '{print $3}'`;\
	do \
		check_queue=`qstat -j $step | awk '$1 ~/scheduling/'| grep cannot| wc -l`
			if [ $check_queue -eq 0 ]
				then  
		startlong=`sudo -u seqware -i /usr/bin/qstat -j $step | awk '$1 ~/submission_time/'| awk '{print $2, $3, $4, $5, $6, $7}'`;\
		startshort=`date -d "$startlong" +"%s"`;\
		curtime=`date +%s`;\
		diff=$(($curtime-startshort));\
		hours=$((diff / 3600));\
		step_name=`sudo -u seqware -i /usr/bin/qstat -f | awk -v var=$step '$1 ~ var {print $3}'`;\
		work_dir=`sudo -u seqware -i /home/seqware/bin/seqware workflow report --accession $accession| grep -B1 $workflow | grep "Workflow Run Working Dir" | awk -F"|" '{print $2}'`;\
		
		case $step_name in
			GNOSDown*)	log_file_small=`oozie job -info $workflow -oozie http://localhost:11000/oozie | grep RUNNING| grep 0000| awk -F"@" '{print $2}'| cut -f1 -d" "`	
					log_file_long=`find $work_dir -name "GNOSDownload_*.stderr"`
					download_rate=`grep Status $log_file_long | tail -5 | awk '{ if ($10 == "MB/s") sum += $9*1024; else sum += $9; n++ } END { if (n > 0) print sum / n; }'`
					if [ $hours -gt $gtdownload ]
        				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name has been running for $hours hours and downloading at a rate of $download_rate kB/s."
					exit 2
					elif (( $download_rate == "0" ))
        				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name is downloading at a rate of $download_rate kB/s"
					exit 2
					elif (( $download_rate -lt $download_rate_alert ))
        				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name is downloading at a rate of $download_rate kB/s"
					exit 2
				fi 
			;;
# Kept this as example, but it has to be replaced with Sanger specific checks 
	#		merge*)	if [ $hours -gt $mergeBAM ]
        #				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name has been running for $hours hours"
	#				exit 2
	#				else echo "No problems detected."
	#				exit 0
	#			fi 
	#		;;
			vcfUpload*)	log_file_small=`oozie job -info $workflow -oozie http://localhost:11000/oozie | grep RUNNING| grep 0000| awk -F"@" '{print $2}'| cut -f1 -d" "`	
					log_file_long=`find $work_dir -name "vcfUpload_*.stderr"`
					upload_rate=`grep Status $log_file_long | tail -5 | awk '{ if ($10 == "MB/s") sum += $9*1024; else sum += $9; n++ } END { if (n > 0) print sum / n; }'`
					if [ $hours -gt $upload ]
        				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name has been running for $hours hours and is uploading at a rate of $upload_rate kB/s."
					exit 2
					elif (( $upload_rate == "0" ))
                                        then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name is downloading at a rate of $download_rate kB/s"
                                        exit 2
					elif (( $upload_rate -lt $upload_rate_alert ))
        				then echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name is uploading at a rate of $upload_rate kB/s."
				fi 
			;;
			*)  echo "The job with Workflow Run Engine ID $workflow step ID $step doing $step_name has been running for $hours hours"
			;;
		esac
	   fi
	done
done
