#!/bin/sh
#
# It alerts if there are no workflows running, or if there are any workflows that have been running for too long
#set -x

# First, get the jobID, status and run time
jobid=`sudo -u seqware -i /home/seqware/bin/seqware workflow report --accession 2 | grep -B1 -A18 running | egrep "Run SWID|Run Status|Run Time"`

# Still to do
# The running jobs should be investigated further to see if they have been running longer than a parameterized threshold
# If yes, then get the step number and exit with "Critical"
# If the job threshold has not been reached, get the working step and the time has it been working on it and compare it with a parameterized threshold
# If the job has been working on that job longer than the threshold, exit with "Critical" and JobID+StepID

# The threshold should be provided as a separate file, e.g.
# playbook_root/roles/client/vars/aws_threshold.yml
#  -- 
#   - include vars\aws_threshold.yml

# cat playbook_root/roles/client/vars/aws_threshold.yml
#---
# total_job_time:  4d
# step1_job_time:  4h
# step2_job_time:  4h
# step3_job_time:  8h
# step4_job_time:  12h
#....

if [ -z $jobid ]
	then 
		echo "There are no jobs running, please investigate why!"
		exit 2
	else
		days=`echo $jobid | grep "Run Time"| awk -F":" '{print $2}'| awk '{print $1}'`
		days_clean=`echo "${days: -1}"`

		if [ $days_clean == "d" ]
			then days=`echo "${first: 0:1}"` 
				if [ $days -gt {{ total_max_workflow_duration }} ]
					then echo "The job has been running for more than $days days, please investigate!"
					exit 2
				else
  					echo "All seqware jobs are fine."
    					exit 0
				fi
		fi

fi

